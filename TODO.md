## TODO List

- [ ] **Initialize Resume Database:**
  - Design and implement a database schema (e.g., SQLite, PostgreSQL) to store resume-related information.
  - Key fields should include:
    - `resume_id` (Primary Key)
    - `user_id` (if user accounts are implemented later)
    - `file_name` (original name of the uploaded file)
    - `file_path` (storage location, e.g., local path or cloud storage URI)
    - `extracted_text` (full text content of the resume)
    - `word_count`
    - `upload_timestamp`
    - `last_validated_timestamp`
    - `validation_status` (e.g., 'pending', 'valid', 'invalid', 'extraction_failed')
    - `validation_details` (e.g., specific reasons for failure, confidence scores)

## Feature: Resume Upload & Initial Processing

- [ ] **1. Integrate Resume Database into Upload Process:**
  - Modify `ResumeHandler` to save resume details (file path, extracted text, initial validation) into the new database upon successful upload.
  - Ensure that if validation fails (including text extraction failure), the file is still recorded, but its status is marked appropriately.

- [ ] **2. Enhance UI Navigation for Resume Management:**
  - Implement clear navigation links between the main Chat interface (`index.html`) and the Resume Upload page (`upload.html`).
  - Ensure the active page is highlighted in the navigation bar on both pages.
  - Consider a dedicated "Manage Resumes" or "My Resumes" page if multiple resume uploads per user are envisioned.

## Feature: AI-Powered Resume Analysis & FAQ Generation

- [ ] **1. Develop AI Interaction Module for Resumes:**
  - Create a new module or class responsible for sending resume text to the designated Large Language Model (LLM).
  - Define a clear API for this module (input: resume text, output: structured analysis results).

- [ ] **2. Implement LLM-based Resume Validation & FAQ Extraction:**
  - **Task:** Send extracted resume text to the LLM.
  - **Prompt Engineering:** Develop effective prompts to instruct the LLM to:
    - Perform a comprehensive validation of the resume content (e.g., completeness, clarity, presence of key sections like experience, education, skills, contact info).
    - Identify and extract potential Frequently Asked Questions (FAQs) directly from the resume content. These FAQs should be relevant to a job application or an interview context.
    - Generate concise and accurate answers for these extracted FAQs based *only* on the resume's content.
  - **Output:** The LLM should return structured data (e.g., JSON) containing:
    - Overall validation assessment (e.g., score, feedback on strengths/weaknesses).
    - A list of {question, answer} pairs for the generated FAQs.

## Feature: User Review and Augmentation of AI-Generated FAQs

- [ ] **1. Create FAQ Review and Editing Interface:**
  - Develop a new HTML page and corresponding Flask route (e.g., `/review_faq/<resume_id>`).
  - This page will display:
    - The LLM's validation feedback on the resume.
    - The list of suggested FAQs and their answers generated by the LLM.
  - Provide UI elements for the user to:
    - Review each suggested FAQ.
    - Edit the question or answer of an LLM-generated FAQ.
    - Delete an LLM-generated FAQ.
    - Add entirely new question-answer pairs manually.

- [ ] **2. Implement Logic for User FAQ Modifications:**
  - Develop backend logic to handle user submissions from the FAQ review page.
  - Update the temporarily stored or processed FAQs based on user edits, additions, or deletions.

## Feature: Finalizing and Storing FAQs

- [ ] **1. Store Approved FAQs:**
  - Once the user has reviewed and finalized the FAQs (either LLM-generated or manually added), implement functionality to store them persistently.
  - **Decision Point:** Determine where to store these FAQs:
    - Option A: In the existing `faq_responses.json` (requires careful merging and ID management).
    - Option B: In a new database table dedicated to FAQs, potentially linked to `resume_id` or `user_id`.
    - Option C: A hybrid approach.
  - Ensure that stored FAQs include the question, the answer, and potentially a source (e.g., 'llm_generated_resume_x', 'user_added').

  